name: llava
path: llava-hf/llava-1.5-13b-hf
processor_path: "${model.path}"
dtype: bfloat16
attn_impl: flash_attention_2